{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "import utils as pic\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init     = 1.e-5    # Initial learning rate  \n",
    "batch_size  = 100       # Training batch size\n",
    "train_size  = 2000     # Training size\n",
    "valid_size  = 1000     # Validation size\n",
    "test_size   = 1000     # Test size\n",
    "epochs      = 20       # Number of epochs\n",
    "doGPU       = False    # Use GPU\n",
    "tmin        = -0.1    # Minimum time cutoff\n",
    "tmax        = 0.1     # Maximum time cutoff\n",
    "tstep       = 0.0085   # Time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set range of training set\n",
    "train_start, train_stop = 0, train_size\n",
    "assert train_stop > train_start\n",
    "assert (len(pic.decays)*train_size) % batch_size == 0\n",
    "X_train, y_train = pic.load_data(train_start,train_stop)\n",
    "\n",
    "# Set range of validation set\n",
    "valid_start, valid_stop = 160000, 160000+valid_size\n",
    "assert valid_stop  >  valid_start\n",
    "assert valid_start >= train_stop\n",
    "X_valid, y_valid = pic.load_data(valid_start,valid_stop)\n",
    "\n",
    "# Set range of test set\n",
    "test_start, test_stop = 204800, 204800+test_size\n",
    "assert test_stop  >  test_start\n",
    "assert test_start >= valid_stop\n",
    "X_test, y_test = pic.load_data(test_start,test_stop)\n",
    "\n",
    "samples_requested = len(pic.decays) * (train_size + valid_size + test_size)\n",
    "samples_available = len(y_train) + len(y_valid) + len(y_test)\n",
    "assert samples_requested == samples_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_t_train, maxframes, time_bins = pic.timeordered_BC(X_train, cumulative=True, min_t=tmin, max_t=tmax, t_step=tstep )\n",
    "\n",
    "scaler = pic.MinMaxScaler(0.001).fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "y_b_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_t_valid, maxframes, time_bins = pic.timeordered_BC(X_valid, cumulative=True, min_t=tmin, max_t=tmax, t_step=tstep )\n",
    "X_valid = scaler.transform(X_valid)\n",
    "y_b_valid = to_categorical(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_t_test, _, _ = pic.timeordered_BC(X_test, cumulative=True, min_t=tmin, max_t=tmax, t_step=tstep)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_b_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 24, 32, 32)]      0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 24, 32, 32, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 24, 32, 32, 16)    432       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 24, 32, 32, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 12, 16, 16, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 12, 16, 16, 8)     3456      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 12, 16, 16, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 6, 8, 8, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 6, 8, 8, 8)        1728      \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 6, 8, 8, 8)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3 (None, 12, 16, 16, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 12, 16, 16, 16)    3456      \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 12, 16, 16, 16)    0         \n",
      "_________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3 (None, 24, 32, 32, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 24, 32, 32, 1)     432       \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 24, 32, 32)        0         \n",
      "=================================================================\n",
      "Total params: 9,504\n",
      "Trainable params: 9,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = keras.Input(shape=(maxframes, 32, 32)) # shape (24,32,32,1)\n",
    "\n",
    "def encoding_layer(previous,nfilters,conv_shape,pool_shape):\n",
    "    x = layers.Conv3D(nfilters, conv_shape, padding='same', use_bias=False)(previous)\n",
    "    x = layers.ReLU()(x)\n",
    "    encoded = layers.MaxPooling3D(pool_shape, padding='same')(x)\n",
    "    return encoded\n",
    "\n",
    "# Encoder\n",
    "x = layers.Reshape((maxframes, 32, 32, 1))(input_img)\n",
    "encoded = encoding_layer(x,16,3,2)\n",
    "encoded = encoding_layer(encoded,8,3,2)\n",
    "# encoded = encoding_layer(encoded,8,3,2)\n",
    "# Encoded shape (3,4,4,8)\n",
    "\n",
    "def decoding_layer(previous,nfilters,conv_shape,samp_shape):\n",
    "    x = layers.Conv3D(nfilters,conv_shape, padding='same', use_bias=False)(previous)\n",
    "    x = layers.ReLU()(x)\n",
    "    decoded = layers.UpSampling3D(samp_shape)(x)\n",
    "    return decoded\n",
    "\n",
    "# decoded = decoding_layer(encoded,8,3,2)\n",
    "decoded = decoding_layer(encoded,8,3,2)\n",
    "decoded = decoding_layer(decoded,16,3,2)\n",
    "decoded = layers.Conv3D(1, (3, 3, 3), activation='relu', padding='same', use_bias=False)(decoded)\n",
    "decoded = layers.Reshape((maxframes, 32, 32))(decoded)\n",
    "# Decoded shape (24,32,32,1)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=lr_init),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "80/80 [==============================] - 204s 3s/step - loss: 0.0046 - accuracy: 0.0455 - val_loss: 0.0037 - val_accuracy: 0.0477\n",
      "Epoch 2/2\n",
      "80/80 [==============================] - 196s 2s/step - loss: 0.0034 - accuracy: 0.0513 - val_loss: 0.0031 - val_accuracy: 0.0520\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    validation_data=(X_valid,X_valid),\n",
    "    epochs=2,\n",
    "    batch_size=50,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reconst = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reconst_flat = np.sum(X_test_reconst,axis=1)\n",
    "X_test_flat = np.sum(X_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(X,mask_zero=True,figax=None):\n",
    "    if figax is None: figax = plt.subplots()\n",
    "    fig,ax = figax \n",
    "    if mask_zero: X = np.where(X==0,np.nan,X)\n",
    "    ax.imshow(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "event = 23\n",
    "\n",
    "fig,axs = plt.subplots(ncols=3,figsize=(10,5))\n",
    "plot_image(X_test_flat[event],figax=(fig,axs[0]))\n",
    "plot_image(X_test_reconst_flat[event],figax=(fig,axs[1]))\n",
    "plot_image(np.abs(X_test_flat[event]-X_test_reconst_flat[event]),figax=(fig,axs[2]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dc50badf6bcf34ee37feb4ddab24eb1b71716d96fc6cae89d10c22f5e3462c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
